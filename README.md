# Tokenizing-BBC-news

This project is part from Natural Language Processing in TensorFlow course by deeplearning.ai.

For more information see this [link](https://www.coursera.org/learn/natural-language-processing-tensorflow)

# Definition

- Tokenization converts the data from its text form to numbers form.
- In this project, BBC news dataset is tokenized so it can be used in a lot of applications.
